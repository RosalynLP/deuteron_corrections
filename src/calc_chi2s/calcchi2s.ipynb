{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes: \n",
    "# 1. You need to put the covariance matrix csv files in this folder\n",
    "# 2. Some of the cells can be a bit computationally expensive, hence I save the output \n",
    "#    as pickles to be easily reloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validphys.calcutils import calc_chi2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from validphys.core import ExperimentSpec, FKTableSpec\n",
    "from validphys import results\n",
    "from validphys.loader import Loader\n",
    "from validphys.api import API\n",
    "import scipy.linalg as la\n",
    "\n",
    "# Reading in deuteron covmats\n",
    "it0 = pd.read_csv(\n",
    "    \"covmatrix_global_proton.csv\",\n",
    "    dtype={\"user_id\": float},\n",
    "    index_col=[0,1,2], header=[0,1,2]\n",
    ")\n",
    "\n",
    "it1dw = pd.read_csv(\n",
    "    \"covmatrix_ite.csv\",\n",
    "    dtype={\"user_id\": float},\n",
    "    index_col=[0,1,2], header=[0,1,2]\n",
    ")\n",
    "\n",
    "it1shift = pd.read_csv(\n",
    "    \"covmatrix_shift_ite_1.csv\",\n",
    "    dtype={\"user_id\": float},\n",
    "    index_col=[0,1,2], header=[0,1,2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming experiment DYE886R -> DYE886 to correct covariance matrix.\n",
    "# Commented out because it was changed manually in the csv file.\n",
    "#tups = []\n",
    "# for tup in it0.index:\n",
    "#     if tup[0] == \"DYE886R\":\n",
    "#         newtup = (\"DYE886\", tup[1], tup[2])\n",
    "#     else: newtup = tup\n",
    "#     tups.append(newtup)\n",
    "# newindex = pd.MultiIndex.from_tuples(tups, names=(\"experiment\", \"dataset\", \"id\"))\n",
    "\n",
    "# Relabelling dataframes because otherwise column index is a string rather than an int and this causes problems\n",
    "# down the line\n",
    "it0 = pd.DataFrame(it0.values, index=it0.index, columns=it0.index)\n",
    "it1dw = pd.DataFrame(it1dw.values, index=it1dw.index, columns=it1dw.index)\n",
    "it1shift = pd.DataFrame(it1shift.values, index=it1shift.index, columns=it1shift.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset index so we can wrap everything in a dataframe to prevent misalignment\n",
    "dsindex_bl = API.experiments_index(experiments={\"from_\": \"fit\"},\n",
    "                                   fit=\"200609-ern-001\",\n",
    "                                   theoryid=53,\n",
    "                                   use_cuts=\"fromfit\",\n",
    "                                   pdf={\"from_\": \"fit\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting D and T to calculate diffs\n",
    "datth_bl = API.experiments_results(experiments={\"from_\": \"fit\"},\n",
    "                                   fit=\"200609-ern-001\",\n",
    "                                   theoryid=53,\n",
    "                                   use_cuts=\"fromfit\",\n",
    "                                   pdf={\"from_\": \"fit\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = []\n",
    "for experiment in datth_bl:\n",
    "    diffs.append(experiment[0].central_value - experiment[1].central_value)\n",
    "diffs_bl = pd.DataFrame([item for sublist in diffs for item in sublist], index=dsindex_bl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "datth_it0 = API.experiments_results(experiments={\"from_\": \"fit\"},\n",
    "                            fit=\"NNPDF31_nnlo_as_0118_global_deut\",\n",
    "                            theoryid=53,\n",
    "                            use_cuts=\"fromfit\",\n",
    "                            pdf={\"from_\": \"fit\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = []\n",
    "for experiment in datth_it0:\n",
    "    diffs.append(experiment[0].central_value - experiment[1].central_value)\n",
    "diffs_it0 =pd.DataFrame([item for sublist in diffs for item in sublist], index=dsindex_bl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datth_it1dw = API.experiments_results(experiments={\"from_\": \"fit\"},\n",
    "                                     fit=\"NNPDF31_nnlo_as_0118_global_deut_ite\",\n",
    "                                     theoryid=53,\n",
    "                                     use_cuts=\"fromfit\",\n",
    "                                     pdf={\"from_\": \"fit\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = []\n",
    "for experiment in datth_it1dw:\n",
    "    diffs.append(experiment[0].central_value - experiment[1].central_value)\n",
    "diffs_it1dw =pd.DataFrame([item for sublist in diffs for item in sublist], index=dsindex_bl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datth_it1shifted = API.experiments_results(experiments={\"from_\": \"fit\"},\n",
    "                                     fit=\"NNPDF31_nnlo_as_0118_global_deut_ite_shift\",\n",
    "                                     theoryid=53,\n",
    "                                     use_cuts=\"fromfit\",\n",
    "                                     pdf={\"from_\": \"fit\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = []\n",
    "for experiment in datth_it1shifted:\n",
    "    diffs.append(experiment[0].central_value - experiment[1].central_value)\n",
    "diffs_it1shifted =pd.DataFrame([item for sublist in diffs for item in sublist], index=dsindex_bl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'diffs_bl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-cfa241326ca9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Pickling items for easy reloading - from now on can skip cells 5-13\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdiffs_bl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"diffs_bl.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdiffs_it0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"diffs_it0.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdiffs_it1dw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"diffs_it1dw.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'diffs_bl' is not defined"
     ]
    }
   ],
   "source": [
    "# Pickling items for easy reloading - from now on can skip cells 5-13\n",
    "import pickle\n",
    "pickle.dump( diffs_bl, open( \"diffs_bl.p\", \"wb\" ) )\n",
    "pickle.dump( diffs_it0, open( \"diffs_it0.p\", \"wb\" ) )\n",
    "pickle.dump( diffs_it1dw, open( \"diffs_it1dw.p\", \"wb\" ) )\n",
    "pickle.dump( diffs_it1shifted, open( \"diffs_it1shifted.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloading pickles\n",
    "diffs_bl = pd.read_pickle(\"diffs_bl.p\")\n",
    "diffs_it0 = pd.read_pickle(\"diffs_it0.p\")\n",
    "diffs_it1dw = pd.read_pickle(\"diffs_it1dw.p\")\n",
    "diffs_it1shifted = pd.read_pickle(\"diffs_it1shifted.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diffs_it0 = pd.DataFrame(diffs_it0.values, index=C_orig.index)\n",
    "#diffs_bl = pd.DataFrame(diffs_bl.values, index=newindex)\n",
    "#diffs_it1dw = pd.DataFrame(diffs_it1dw.values, index=newindex)\n",
    "#diffs_it1shifted = pd.DataFrame(diffs_it1shifted.values, index=newindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s1303034/miniconda3/envs/nnpdf-dev/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3417: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/home/s1303034/miniconda3/envs/nnpdf-dev/lib/python3.7/site-packages/reportengine/api.py:43: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  return self.__call__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Loading original covmat (experimental)\n",
    "C_orig = API.experiments_covmat( experiments={\"from_\": \"fit\"},\n",
    "                                   fit =\"200609-ern-001\",\n",
    "                                   theoryid=53,\n",
    "                                   use_cuts=\"fromfit\",\n",
    "                                   pdf={\"from_\": \"fit\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of datasets in orig covmat and in deuteron fit\n",
    "dslist = list(dict.fromkeys([tup[1] for tup in C_orig.index]))\n",
    "dslist_small = list(dict.fromkeys([tup[1] for tup in it0.index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extend the dimensions of a small covmat to that of a big covmat, filling in the empty entries with 0s\n",
    "def extend_covmat(dslist, bigcovmat, smallcovmat):\n",
    "    # Make dimensions match those of exp covmat. First make empty df of\n",
    "    # exp covmat dimensions\n",
    "    empty_df = pd.DataFrame(0, index=C_orig.index, columns=C_orig.index)\n",
    "    covmats = []\n",
    "    for ds1 in dslist:\n",
    "        for ds2 in dslist:\n",
    "            if (ds1 in smallcovmat.index.unique(level=1)) and (ds2 in smallcovmat.index.unique(level=1)):\n",
    "                # If both datasets are in the small covmat, take the relevant ds covmat out the small covmat\n",
    "                covmat = smallcovmat.xs(ds1,level=1, drop_level=False).T.xs(ds2, level=1, drop_level=False).T\n",
    "            else:\n",
    "                # If not, make a ds covmat of 0s of the relevant dimensions \n",
    "                covmat = empty_df.xs(ds1,level=1, drop_level=False).T.xs(ds2, level=1, drop_level=False).T\n",
    "            covmat.reset_index()\n",
    "            # covmats is a list of the ds covmats in order\n",
    "            covmats.append(covmat)\n",
    "    # Chunks is a list of lists of covmats, one list of covmats for each dataset\n",
    "    chunks = []\n",
    "    for x in range(0, len(covmats), len(dslist)):\n",
    "        chunk = covmats[x:x+len(dslist)]\n",
    "        chunks.append(chunk)\n",
    "    # Concatenate each chunk into a strip so we have N_dataset strips of covmat\n",
    "    strips = []\n",
    "    i=0\n",
    "    for chunk in chunks:\n",
    "        i=i+1\n",
    "        strip = pd.concat(chunk, axis=1)\n",
    "        strips.append(strip.T)\n",
    "    strips.reverse()\n",
    "    # Stack the strips to construct the full covmat\n",
    "    full_df = pd.concat(strips, axis=1)\n",
    "    full_df = full_df.reindex(bigcovmat.index)\n",
    "    full_df = ((full_df.T).reindex(bigcovmat.index)).T\n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extending the deuteron covmats to match size of C_orig\n",
    "it0total = extend_covmat(dslist, C_orig, it0)\n",
    "it1dwtotal = extend_covmat(dslist, C_orig, it1dw)\n",
    "it1shifttotal = extend_covmat(dslist, C_orig, it1shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.17868292])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating total chi2s\n",
    "calc_chi2(la.cholesky(C_orig, lower=True), diffs_bl)/len(diffs_bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.16000901])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_chi2(la.cholesky(it0total+C_orig, lower=True), diffs_it0)/len(diffs_it0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.15869441])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_chi2(la.cholesky(it1dwtotal+C_orig, lower=True), diffs_it1dw)/len(diffs_it1dw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.16601756])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_chi2(la.cholesky(it1shifttotal+C_orig, lower=True), diffs_it1shifted)/len(diffs_it1shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return chi2s by dataset\n",
    "def chi2s_by_dataset(covmat, diffs):\n",
    "    chi2s = []\n",
    "    for dataset in dslist:\n",
    "        dscovmat = covmat.xs(dataset,level=1, drop_level=False).T.xs(dataset, level=1, drop_level=False).T\n",
    "        dsdiffs = diffs.xs(dataset, level=1, drop_level=False)\n",
    "        chi2 = calc_chi2(la.cholesky(dscovmat, lower=True), dsdiffs)/len(dsdiffs)\n",
    "        chi2s.append((dataset, chi2[0]))\n",
    "    chi2table = pd.DataFrame(chi2s, columns=[\"dataset\", \"chi2\"])\n",
    "    return chi2table\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chi2s_by_dataset(C_orig+it1dwtotal, diffs_it1dw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptions = {\"NMC\":[\"NMC\", \"NMCPD\"], \"SLAC\": [\"SLACP\", \"SLACD\"], \"BCDMS\":[\"BCDMSP\", \"BCDMSD\"]}\n",
    "explist = list(dict.fromkeys([tup[0] for tup in C_orig.index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2s_by_custom_grouping(covmat, diffs, exceptions, name):\n",
    "    chi2s = []\n",
    "    index = []\n",
    "    lens = []\n",
    "    for exp in explist:\n",
    "        if exp in exceptions:\n",
    "            datasets = exceptions[exp]\n",
    "            for dataset in datasets:\n",
    "                dscovmat = covmat.xs(dataset,level=1, drop_level=False).T.xs(dataset, level=1, drop_level=False).T\n",
    "                dsdiffs = diffs.xs(dataset, level=1, drop_level=False)\n",
    "                chi2 = calc_chi2(la.cholesky(dscovmat, lower=True), dsdiffs)/len(dsdiffs)\n",
    "                index.append(dataset)\n",
    "                chi2s.append(chi2[0])\n",
    "                lens.append(len(dsdiffs.values))\n",
    "        else:\n",
    "            dscovmat = covmat.xs(exp,level=0, drop_level=False).T.xs(exp, level=0, drop_level=False).T\n",
    "            dsdiffs = diffs.xs(exp, level=0, drop_level=False)\n",
    "            chi2 = calc_chi2(la.cholesky(dscovmat, lower=True), dsdiffs)/len(dsdiffs)\n",
    "            index.append(exp)\n",
    "            chi2s.append(chi2[0])\n",
    "            lens.append(len(dsdiffs.values))\n",
    "    ndatdf = pd.DataFrame(lens, index=index, columns=[r\"$N_{dat}$\"])\n",
    "    chi2table = pd.DataFrame(chi2s, index=index, columns=[f\"{name}\"])\n",
    "    return chi2table, ndatdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "blchi2, ndatdf = chi2s_by_custom_grouping(C_orig, diffs_bl, exceptions, \"Baseline\")\n",
    "it0chi2, dummy = chi2s_by_custom_grouping(C_orig+it0total, diffs_it0, exceptions, \"proton-ite0\")\n",
    "it1dwchi2, dummy = chi2s_by_custom_grouping(C_orig+it1dwtotal, diffs_it1dw, exceptions, \"proton-ite1 deweighted\")\n",
    "it1shiftchi2, dummy = chi2s_by_custom_grouping(C_orig+it1shifttotal, diffs_it1shifted, exceptions, \"proton-ite1 shifted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$N_{dat}$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NMC</th>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMCPD</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLACP</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLACD</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BCDMSP</th>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BCDMSD</th>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHORUS</th>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NTVDMN</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HERACOMB</th>\n",
       "      <td>1145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HERAF2CHARM</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2BOTTOM</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DYE886</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DYE605</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDF</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D0</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATLAS</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMS</th>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LHCb</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             $N_{dat}$\n",
       "NMC                204\n",
       "NMCPD              121\n",
       "SLACP               33\n",
       "SLACD               34\n",
       "BCDMSP             333\n",
       "BCDMSD             248\n",
       "CHORUS             832\n",
       "NTVDMN              76\n",
       "HERACOMB          1145\n",
       "HERAF2CHARM         37\n",
       "F2BOTTOM            29\n",
       "DYE886             104\n",
       "DYE605              85\n",
       "CDF                 29\n",
       "D0                  45\n",
       "ATLAS              211\n",
       "CMS                327\n",
       "LHCb                85"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndatdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "{} &  \\$N\\_\\{dat\\}\\$ &  Baseline &  proton-ite0 &  proton-it1 deweighted &  proton-it1 shifted \\\\\n",
      "\\midrule\n",
      "NMC         &        204 &  1.540300 &     1.550128 &               1.542341 &            1.551019 \\\\\n",
      "NMCPD       &        121 &  1.005335 &     0.790967 &               0.784046 &            0.816576 \\\\\n",
      "SLACP       &         33 &  0.877711 &     0.928025 &               0.914090 &            0.910228 \\\\\n",
      "SLACD       &         34 &  0.715824 &     0.496624 &               0.493564 &            0.491721 \\\\\n",
      "BCDMSP      &        333 &  1.297092 &     1.295474 &               1.287699 &            1.297873 \\\\\n",
      "BCDMSD      &        248 &  1.102493 &     0.978205 &               0.908407 &            0.955034 \\\\\n",
      "CHORUS      &        832 &  1.151979 &     1.134715 &               1.141808 &            1.144278 \\\\\n",
      "NTVDMN      &         76 &  0.756749 &     0.810845 &               0.773429 &            0.894649 \\\\\n",
      "HERACOMB    &       1145 &  1.159849 &     1.158177 &               1.156687 &            1.158366 \\\\\n",
      "HERAF2CHARM &         37 &  1.424441 &     1.430991 &               1.427807 &            1.438082 \\\\\n",
      "F2BOTTOM    &         29 &  1.110043 &     1.111679 &               1.112241 &            1.111532 \\\\\n",
      "DYE886      &        104 &  1.167306 &     1.101173 &               1.062911 &            1.037562 \\\\\n",
      "DYE605      &         85 &  1.108819 &     1.096547 &               1.094888 &            1.117800 \\\\\n",
      "CDF         &         29 &  1.363833 &     1.341780 &               1.354069 &            1.326584 \\\\\n",
      "D0          &         45 &  1.178826 &     1.152300 &               1.156223 &            1.173696 \\\\\n",
      "ATLAS       &        211 &  1.132017 &     1.114821 &               1.122128 &            1.098879 \\\\\n",
      "CMS         &        327 &  1.151727 &     1.128811 &               1.143523 &            1.177563 \\\\\n",
      "LHCb        &         85 &  1.624244 &     1.586900 &               1.668296 &            1.654786 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chi2tab = pd.concat([ndatdf, blchi2, it0chi2, it1dwchi2, it1shiftchi2], axis=1)\n",
    "print(chi2tab.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
